//
//  AudioIOManager.swift
//  Openock
//
//  Created by JiJooMaeng on 10/26/25.
//

/*
 Audio IO Manager
 
 Abstract:
 Manages CoreAudio IO operations including audio device IO proc, buffer processing,
 and audio preprocessing (HPF and noise gate).
 */

import Foundation
import AVFoundation
import CoreAudio

// MARK: - Audio Preprocessor

// HPFê°€ 120í—¤ë¥´ì¸ (ì €ìŒ) ì´í•˜ë¥¼ ì˜ë¼ë‚´ëŠ” ì—­í• ì¸ë° ì´ê±¸ ì™„í™”í•˜ê² ë‹¤
// ë…¸ì´ì¦ˆ ê²Œì´íŠ¸ëŠ” ë™ì ìœ¼ë¡œ ì†Œë¦¬ í¬ê¸° ë°›ì•„ì„œ íŠ¹ì • ì†Œë¦¬ í¬ê¸° ì´í•˜ì´ë©´ ì˜ë¼ë‚´ëŠ” ì—­í• ì¸ë° ì´ê±¸ ì™„í™”í•˜ê² ë‹¤
// ëª¨ë…¸í™”ëŠ” ìŠ¤í…Œë ˆì˜¤ì¸ ê²½ìš°ê°€ ë§ê³  ì´ ê²½ìš° ëª©ì†Œë¦¬ëŠ” ì„¼í„° ë°°ê²½ìŒì€ ì¢Œ ìš° ë°°ì¹˜ì¸ë° ì™œê³¡ì´ ì ë„ë¡ ì¢Œ ìš°ë¥¼ í‰ê· ë‚´ë²„ë¦¬ëŠ”ê±°ì„
// ì˜í™”, ìœ íŠœë¸Œ, ìŒì•… ëŒ€ë¶€ë¶„ì˜ ìŠ¤í…Œë ˆì˜¤ ì˜¤ë””ì˜¤ëŠ” mid-side ë°©ì‹ì„
// left = mid + side, right = mid - side ê·¸ë˜ì„œ ë”í•´ì„œ ë‚˜ëˆ„ë©´ ì¤‘ì•™ ì¦í­ì´ ë  ê²ƒ ê°™ë‹¤ ì´ëŸ° ì ‘ê·¼ì„ ã…‡ã…‡

fileprivate final class AudioPreprocessor {
  private let sampleRate: Double
  private let channels: Int
  private let frameSamples: Int
  private var x1: [Float]
  private var y1: [Float]
  private let hpAlpha: Float
  private var emaRms: Float = 0.0
  private let emaA: Float = 0.95
  
  // ê²Œì´íŠ¸ ê´€ë ¨ (ê¸°ë³¸ OFF)
  private let useNoiseGate: Bool = false
  private let gateAttenuation: Float = pow(10.0, -6.0/20.0) // -6 dB ì •ë„ë§Œ ì‚´ì§ ì¤„ì„
  private let gateOpenRatio: Float = 1.5
  
  // ì»·ì˜¤í”„ ì™„í™”: 90Hz ê¸°ë³¸
  init(sampleRate: Double, channels: Int, frameMs: Int = 20, hpCutoff: Double = 90.0) {
    self.sampleRate = sampleRate
    self.channels = max(1, channels)
    self.frameSamples = max(1, Int((sampleRate * Double(frameMs)) / 1000.0))
    self.x1 = Array(repeating: 0, count: self.channels)
    self.y1 = Array(repeating: 0, count: self.channels)
    let dt = 1.0 / sampleRate
    let rc = 1.0 / (2.0 * Double.pi * hpCutoff)
    self.hpAlpha = Float(rc / (rc + dt))
  }
  
  func process(_ inBuf: AVAudioPCMBuffer) -> AVAudioPCMBuffer {
    let n = Int(inBuf.frameLength)
    guard n > 0 else { return inBuf }

    // ì¶œë ¥ ë²„í¼ ì¤€ë¹„ (ëª¨ë…¸ í˜¹ì€ ë™ì¼ í¬ë§· ìœ ì§€)
    let outFormat: AVAudioFormat
    if channels > 1 {
      // ëª¨ë…¸í™”ëœ í¬ë§· ìƒì„±
      outFormat = AVAudioFormat(commonFormat: .pcmFormatFloat32,
                                sampleRate: inBuf.format.sampleRate,
                                channels: 1,
                                interleaved: false)!
    } else {
      outFormat = inBuf.format
    }

    guard let out = AVAudioPCMBuffer(pcmFormat: outFormat, frameCapacity: inBuf.frameLength) else {
      return inBuf
    }
    out.frameLength = inBuf.frameLength

    guard let srcBase = inBuf.floatChannelData else { return inBuf }
    guard let dstBase = out.floatChannelData else { return inBuf }

    // ----- ëª¨ë…¸í™” (ìŠ¤í…Œë ˆì˜¤ì¸ ê²½ìš°ì—ë§Œ) -----
    if channels > 1 {
      let L = srcBase[0]
      let R = srcBase[1]
      let dst = dstBase[0]
      for i in 0..<n {
        dst[i] = 0.5 * (L[i] + R[i]) // ì¤‘ì•™ ê°•ì¡°
      }
    } else {
      // ëª¨ë…¸ ì…ë ¥ì´ë©´ ê·¸ëŒ€ë¡œ ë³µì‚¬
      let src = srcBase[0]
      let dst = dstBase[0]
      dst.assign(from: src, count: n)
    }

    // ----- HPF ì ìš© (90Hz) -----
    let a = hpAlpha
    var prevX: Float = x1[0]
    var prevY: Float = y1[0]
    let dst = dstBase[0]
    for i in 0..<n {
      let x = dst[i]
      let y = a * (prevY + x - prevX)
      dst[i] = y
      prevX = x
      prevY = y
    }
    x1[0] = prevX
    y1[0] = prevY

    // ----- Noise Gate (ê¸°ë³¸ OFF) -----
    guard useNoiseGate else { return out }
    var sum: Float = 0
    for i in 0..<n { sum += dst[i] * dst[i] }
    let rms = sqrt(sum / Float(n))
    if rms < emaRms * 1.5 || emaRms == 0 {
      emaRms = emaA * emaRms + (1 - emaA) * rms
    }
    let openThresh = max(emaRms * gateOpenRatio, 1e-6)
    let applyGate = rms < openThresh
    if applyGate {
      for i in 0..<n { dst[i] *= gateAttenuation }
    }

    return out
  }
}



// MARK: - Audio IO Manager

// âœ… ADD: ì €ì—­(ë² ì´ìŠ¤) ë ˆë²¨ ì½œë°± íƒ€ì…
typealias LowBandCallback = (Float) -> Void

class AudioIOManager {
  
  typealias AudioBufferCallback = (AVAudioPCMBuffer) -> Void
  typealias AudioLevelCallback = (Float) -> Void
  
  private var deviceID: AudioObjectID = kAudioObjectUnknown
  private var ioProcID: AudioDeviceIOProcID?
  private var audioFormat: AVAudioFormat?
  private var preproc: AudioPreprocessor?
  private var preprocEnabled: Bool = true
  
  private var bufferCallback: AudioBufferCallback?
  private var levelCallback: AudioLevelCallback?
  private var bufferCallCount = 0
  var isPaused = false

  // âœ… ADD: ì €ì—­(ë² ì´ìŠ¤) ë ˆë²¨ ì „ì†¡ìš© ìƒíƒœ
  private var lowBandCallback: LowBandCallback?
  private var lpfEnv: Float = 0
  private var lpfAlpha: Float = 0
  private var sampleRateCache: Double = 48000

  // âœ… ADD: ë°´ë“œíŒ¨ìŠ¤(ì €ì»·/ê³ ì»·)ìš© ìƒíƒœ & ê³„ìˆ˜
  private var sigLPF_Low:  Float = 0    // ì €ì»· ê¸°ì¤€ LPF ê²°ê³¼
  private var sigLPF_High: Float = 0    // ê³ ì»· ê¸°ì¤€ LPF ê²°ê³¼
  private var lowAlpha:  Float = 0      // ì €ì»·(ëŠë¦° LPF)
  private var highAlpha: Float = 0      // ê³ ì»·(ë¹ ë¥¸ LPF)
  
  /// Get the audio format for a given device
  func getDeviceFormat(deviceID: AudioObjectID) -> AVAudioFormat? {
    var propertyAddress = AudioObjectPropertyAddress(
      mSelector: kAudioDevicePropertyStreamFormat,
      mScope: kAudioDevicePropertyScopeInput,
      mElement: kAudioObjectPropertyElementMain
    )
    
    var streamFormat = AudioStreamBasicDescription()
    var propertySize = UInt32(MemoryLayout<AudioStreamBasicDescription>.size)
    
    let status = AudioObjectGetPropertyData(deviceID, &propertyAddress, 0, nil, &propertySize, &streamFormat)
    
    guard status == kAudioHardwareNoError else {
      return nil
    }
    
    return AVAudioFormat(
      commonFormat: .pcmFormatFloat32,
      sampleRate: streamFormat.mSampleRate,
      channels: AVAudioChannelCount(streamFormat.mChannelsPerFrame), // ì´ê²Œ ìŠ¤í…Œë ˆì˜¤ì¼ ê²½ìš°ë¥¼ ì €ì¥í•˜ê³  ìˆëŠ” ë¶€ë¶„ì„
      interleaved: false
    )
  }
  
  /// Start audio IO on the specified device
  /// - Parameters:
  ///   - deviceID: The audio device ID
  ///   - bufferCallback: Called when audio buffer is ready
  ///   - levelCallback: Called with audio level updates
  /// - Returns: True if successful
  func startIO(deviceID: AudioObjectID,
               bufferCallback: @escaping AudioBufferCallback,
               levelCallback: @escaping AudioLevelCallback) -> Bool {
    
    print("ğŸ¤ [AudioIOManager] Starting IO on device \(deviceID)...")
    
    self.deviceID = deviceID
    self.bufferCallback = bufferCallback
    self.levelCallback = levelCallback
    self.bufferCallCount = 0
    
    // Get device format
    guard let format = getDeviceFormat(deviceID: deviceID) else {
      print("âŒ [AudioIOManager] Failed to get device format")
      return false
    }
    
    self.audioFormat = format
    print("âœ… [AudioIOManager] Audio format: \(format.sampleRate)Hz, \(format.channelCount) channels")
    
    // Initialize preprocessor
    self.preproc = AudioPreprocessor(
      sampleRate: Double(format.sampleRate),
      channels: Int(format.channelCount),
      frameMs: 20
    )
    
    // Create IO proc
    let managerPtr = UnsafeMutableRawPointer(Unmanaged.passUnretained(self).toOpaque())
    
    var ioProcID: AudioDeviceIOProcID?
    let createStatus = AudioDeviceCreateIOProcID(deviceID, audioIOProc, managerPtr, &ioProcID)
    
    guard createStatus == kAudioHardwareNoError else {
      print("âŒ [AudioIOManager] Failed to create IO proc: \(createStatus)")
      return false
    }
    
    self.ioProcID = ioProcID
    
    // Start IO
    let startStatus = AudioDeviceStart(deviceID, ioProcID)
    guard startStatus == kAudioHardwareNoError else {
      print("âŒ [AudioIOManager] Failed to start audio device: \(startStatus)")
      AudioDeviceDestroyIOProcID(deviceID, ioProcID!)
      self.ioProcID = nil
      return false
    }
    
    print("âœ… [AudioIOManager] Audio IO started successfully")
    return true
  }

  // âœ… ADD: ì €ì—­(ë² ì´ìŠ¤) ì „ìš© ë ˆë²¨ ì½œë°±ê³¼ ì»·ì˜¤í”„ ì„¤ì •  (ë°´ë“œíŒ¨ìŠ¤ 30~90Hz ê·¼ì‚¬ + ì—”ë²Œë¡œí”„ í‰í™œ)
  func setLowBandMonitoring(callback: @escaping LowBandCallback, lowpassCutoffHz: Double = 150.0) {
    self.lowBandCallback = callback
    let fs = max(8_000.0, Double(self.audioFormat?.sampleRate ?? sampleRateCache))

    // ë°´ë“œíŒ¨ìŠ¤ ë²”ìœ„(ë§ì†Œë¦¬ ê¸°ë³¸ìŒì„ í”¼í•˜ê¸° ìœ„í•´ ìƒí•œì„ ë‚®ê²Œ ì¡ìŒ)
    let fLow:  Double = 30.0   // ì €ì»·(í•˜ì´íŒ¨ìŠ¤ ì—­í• )
    let fHigh: Double = 90.0   // ê³ ì»·(ë¡œìš°íŒ¨ìŠ¤ ì—­í• )

    // 1-pole LPF ê³„ìˆ˜: y += Î±(x - y), Î± = 1 - exp(-2Ï€ f / fs)
    self.lowAlpha  = Float(1.0 - exp(-2.0 * Double.pi * fLow  / fs))  // ëŠë¦° LPF
    self.highAlpha = Float(1.0 - exp(-2.0 * Double.pi * fHigh / fs))  // ë¹ ë¥¸ LPF

    // ì—”ë²Œë¡œí”„ í‰í™œ(ëŠë¦¬ê²Œ): 6Hz ê·¼ì²˜
    let envHz = 6.0
    self.lpfAlpha = Float(1.0 - exp(-2.0 * Double.pi * envHz / fs))

    self.sampleRateCache = fs
  }
  
  /// Stop audio IO
  func stopIO() {
    guard let ioProcID = ioProcID else { return }
    
    print("ğŸ›‘ [AudioIOManager] Stopping audio IO...")
    AudioDeviceStop(deviceID, ioProcID)
    AudioDeviceDestroyIOProcID(deviceID, ioProcID)
    self.ioProcID = nil
    self.preproc = nil
    self.bufferCallback = nil
    self.levelCallback = nil
    print("âœ… [AudioIOManager] Audio IO stopped")
  }
  
  /// Process audio buffer from IO proc
  func processAudioBuffer(_ bufferList: UnsafePointer<AudioBufferList>, frameCount: UInt32) {
    if isPaused {
      return
    }
    
    guard let audioFormat = audioFormat else {
      if bufferCallCount == 0 {
        print("âš ï¸ [AudioIOManager] Missing audioFormat")
      }
      return
    }
    
    bufferCallCount += 1
    if bufferCallCount <= 10 || bufferCallCount % 100 == 0 {
      print("ğŸµ [AudioIOManager] Processing buffer #\(bufferCallCount): \(frameCount) frames")
    }
    
    // Create AVAudioPCMBuffer
    guard let pcmBuffer = AVAudioPCMBuffer(
      pcmFormat: audioFormat,
      frameCapacity: AVAudioFrameCount(frameCount)
    ) else {
      return
    }
    
    pcmBuffer.frameLength = AVAudioFrameCount(frameCount)
    
    // Copy audio data from AudioBufferList to AVAudioPCMBuffer
    let abl = UnsafeMutableAudioBufferListPointer(UnsafeMutablePointer(mutating: bufferList))
    let channels = Int(audioFormat.channelCount)
    
    if abl.count == 1, let srcPtr = abl[0].mData?.assumingMemoryBound(to: Float.self), abl[0].mNumberChannels > 1 {
      // Interleaved
      guard let dstBase = pcmBuffer.floatChannelData else { return }
      let totalFrames = Int(frameCount)
      let stride = channels
      for ch in 0..<channels {
        let dst = dstBase[ch]
        var s = srcPtr.advanced(by: ch)
        for f in 0..<totalFrames {
          dst[f] = s.pointee
          s = s.advanced(by: stride)
        }
      }
    } else {
      // Non-interleaved
      for (index, srcBuffer) in abl.enumerated() {
        guard index < channels,
              let dst = pcmBuffer.floatChannelData?[index],
              let srcPtr = srcBuffer.mData?.assumingMemoryBound(to: Float.self) else { continue }
        dst.update(from: srcPtr, count: Int(frameCount))
      }
    }
    
    // Preprocess (HPF + noise gate)
    let enhancedBuffer: AVAudioPCMBuffer
    if preprocEnabled, let pp = preproc {
      enhancedBuffer = pp.process(pcmBuffer)
    } else {
      enhancedBuffer = pcmBuffer
    }
    
    // Send to callback
    bufferCallback?(enhancedBuffer)
    
    // Calculate audio level (every 10 buffers)
    if bufferCallCount % 10 == 0, let channelData = enhancedBuffer.floatChannelData?[0] {
      var sum: Float = 0.0
      let frameLength = Int(enhancedBuffer.frameLength)
      
      var i = 0
      while i < frameLength {
        let sample = channelData[i]
        sum += sample * sample
        i += 4
      }
      
      let avgSum = sum * 4 / Float(frameLength)
      let rms = sqrt(avgSum)
      let db = 20 * log10(max(rms, 0.000001))
      let normalizedLevel = max(0.0, min(1.0, (db + 60) / 60))
      
      levelCallback?(normalizedLevel)
    }

    // âœ… REPLACE: ì €ì—­(ë² ì´ìŠ¤) ì „ìš© ë ˆë²¨ ê³„ì‚° ë° ì „ë‹¬ (ë°´ë“œíŒ¨ìŠ¤ 30~90Hz ê·¼ì‚¬, ë§¤ 10ë²„í¼)
    if bufferCallCount % 10 == 0,
       let lowBandCallback = self.lowBandCallback,
       let srcPtr = pcmBuffer.floatChannelData {
      
      let chCount = Int(audioFormat.channelCount)
      let n = Int(pcmBuffer.frameLength)
      
      if chCount >= 2 {
        let L = srcPtr[0], R = srcPtr[1]
        for i in 0..<n {
          // 1) ëª¨ë…¸ í•©ì„±
          let m = 0.5 * (L[i] + R[i])
          // 2) ë°´ë“œíŒ¨ìŠ¤ ê·¼ì‚¬: ê³ ì»· LPF - ì €ì»· LPF
          sigLPF_Low  += lowAlpha  * (m - sigLPF_Low)   // ì €ì»·(ëŠë¦¼)
          sigLPF_High += highAlpha * (m - sigLPF_High)  // ê³ ì»·(ë¹ ë¦„)
          let band = sigLPF_High - sigLPF_Low           // ëŒ€ëµ 30~90Hz ì„±ë¶„
          // 3) ì—ë„ˆì§€í™” í›„ ì—”ë²Œë¡œí”„ í‰í™œ
          let e = band * band
          lpfEnv += lpfAlpha * (e - lpfEnv)
        }
      } else {
        let M = srcPtr[0]
        for i in 0..<n {
          sigLPF_Low  += lowAlpha  * (M[i] - sigLPF_Low)
          sigLPF_High += highAlpha * (M[i] - sigLPF_High)
          let band = sigLPF_High - sigLPF_Low
          let e = band * band
          lpfEnv += lpfAlpha * (e - lpfEnv)
        }
      }
      
      // 0~1 ìŠ¤ì¼€ì¼ë¡œ ë¶€ë“œëŸ½ê²Œ ì••ì¶• (ë‘”ê°í•˜ê²Œ)
      let k: Float = 10.0
      let bass = 1.0 - expf(-k * max(0, lpfEnv))
      let bassClamped = max(0.0, min(1.0, bass))
      lowBandCallback(bassClamped)
    }
  }
  
  deinit {
    stopIO()
  }
}

// MARK: - Audio IO Proc Callback

private func audioIOProc(
  inDevice: AudioObjectID,
  inNow: UnsafePointer<AudioTimeStamp>,
  inInputData: UnsafePointer<AudioBufferList>,
  inInputTime: UnsafePointer<AudioTimeStamp>,
  outOutputData: UnsafeMutablePointer<AudioBufferList>,
  inOutputTime: UnsafePointer<AudioTimeStamp>,
  inClientData: UnsafeMutableRawPointer?
) -> OSStatus {
  guard let clientData = inClientData else { return kAudioHardwareNoError }
  
  let manager = Unmanaged<AudioIOManager>.fromOpaque(clientData).takeUnretainedValue()
  
  if inInputData.pointee.mNumberBuffers > 0 {
    let buffer = inInputData.pointee.mBuffers
    let frameCount = buffer.mDataByteSize / UInt32(MemoryLayout<Float>.size) / UInt32(buffer.mNumberChannels)
    manager.processAudioBuffer(inInputData, frameCount: frameCount)
  }
  
  return kAudioHardwareNoError
}
